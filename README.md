# üéß DJ-IA: AI-powered DJ System with Advanced Spectral Analysis

DJ-IA is an innovative AI-powered virtual DJ system capable of generating and mixing music in real-time. Using a Large Language Model (LLM) for creative decisions, AI audio models for generation, and Demucs for spectral analysis and isolation, DJ-IA creates dynamic and evolving music sessions in various styles.

‚ö†Ô∏è **IMPORTANT: Proof of Concept** ‚ö†Ô∏è  
This project is currently in proof of concept (POC) stage. Some music styles work better than others, and the code contains unused or experimental sections that haven't been cleaned up yet. The overall architecture is functional but continues to evolve.

## üÜï New Client/Server Architecture with MIDI Clock Sync

DJ-IA now features a **client/server architecture** with **professional MIDI Clock synchronization**! This allows perfect timing sync with DAWs like Bitwig Studio, Ableton Live, and other professional music software.

### How it Works

1. **Server**: Handles AI generation and audio processing
2. **Client**: Manages audio playback and MIDI synchronization
3. **MIDI Clock**: Perfect sync with your DAW for professional timing

![DJ-IA Banner](https://placehold.co/800x200/1a1a1a/FFFFFF?text=DJ-IA+Client%2FServer)

## ‚ú® Features

- üß† Generative AI for DJ decisions and audio generation
- üîä **NEW: Spectral analysis and stem separation for intelligent mixing**
- üé≠ **NEW: Intelligent selection of complementary instruments**
- üéπ **NEW: Respect for LLM stem preferences (even with low energy)**
- üß© **NEW: Support for multiple audio generation models (MusicGen and Stable Audio Open)**
- üéØ **NEW: Client/Server architecture for better performance**
- ‚è±Ô∏è **NEW: Professional MIDI Clock synchronization with DAWs**
- üéõÔ∏è Real-time audio layer management system
- üéöÔ∏è Audio effects: filters, panning, reverb, and delay
- üéµ Support for 10 different musical styles
- üîÑ Synchronized transitions and natural musical progression
- üó£Ô∏è Voice interventions generated by TTS

## üõ†Ô∏è Installation

### Prerequisites

- Python 3.10 or higher
- NVIDIA graphics card with CUDA for optimal performance (recommended)
- At least 8GB of RAM
- At least 2GB of free disk space
- **For MIDI Sync**: Virtual MIDI port software (loopMIDI on Windows)
- **Rubberband CLI**: Required for audio time-stretching

### Platform Support

DJ-IA has been developed and tested on **Windows 11** with the following setup:

- Windows 11 Pro
- NVIDIA RTX GPU with CUDA
- Bitwig Studio for MIDI Clock synchronization
- loopMIDI for virtual MIDI routing

Other platforms (macOS, Linux) should work but may require additional configuration.

### Installing Rubberband CLI

DJ-IA requires the Rubberband command-line tool for high-quality audio time-stretching:

#### Windows

1. **Download Rubberband**: Go to [Rubberband Audio](https://breakfastquay.com/rubberband/) and download the Windows build
2. **Extract**: Extract the archive to a folder (e.g., `C:\Program Files\Rubberband\`)
3. **Add to PATH**: Add the Rubberband `bin` folder to your Windows PATH environment variable:

   - Open **System Properties** ‚Üí **Environment Variables**
   - Edit the **PATH** variable
   - Add the path to Rubberband bin folder (e.g., `C:\Program Files\Rubberband\bin`)
   - **Restart your terminal/command prompt**

4. **Verify installation**: Test that Rubberband is accessible:
   ```cmd
   rubberband --help
   ```

#### macOS (via Homebrew)

```bash
brew install rubberband
```

#### Linux (Ubuntu/Debian)

```bash
sudo apt-get install rubberband-cli
```

**Note**: Without Rubberband CLI properly installed, audio time-stretching features will not work and you may encounter errors during sample processing.

### Setting up the environment

```bash
# Create and activate a virtual environment
python -m venv env

# On Windows
.\env\Scripts\activate

# On macOS/Linux
source env/bin/activate

# Install base dependencies
pip install numpy==1.24.3

# Install PyTorch with CUDA
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# Install necessary tools
pip install setuptools wheel

# Install main libraries
pip install audiocraft pygame llama-cpp-python tqdm librosa

# Install Demucs for source separation
pip install demucs

# Install audio libraries
pip install pyrubberband pedalboard soundfile sounddevice pyttsx3

# Install client dependencies for MIDI sync
pip install mido python-rtmidi requests python-dotenv
```

### MIDI Synchronization Setup (Windows/Bitwig)

For professional MIDI Clock synchronization with Bitwig Studio:

#### 1. Install loopMIDI

- Download and install [loopMIDI](https://www.tobias-erichsen.de/software/loopmidi.html)
- Create a new virtual MIDI port (e.g., "loopMIDI Port")

#### 2. Configure Bitwig Studio

- Add a **HW Instrument** device to any track
- Set **MIDI Output Port** to your loopMIDI port
- **‚úÖ Enable "Send MIDI Clock"**
- This sends tempo sync to DJ-IA Client

#### 3. Other DAWs

The MIDI Clock sync works with any DAW that can send MIDI Clock:

- **Ableton Live**: Link/Tempo/MIDI settings
- **Logic Pro**: MIDI Sync settings
- **Cubase/Nuendo**: MIDI Clock output
- **Reaper**: MIDI Clock send options

### Stable Audio Open (Optional)

‚ö†Ô∏è **IMPORTANT: Dependency Conflict Warning** ‚ö†Ô∏è
Stable Audio Open uses different versions of some dependencies (like numpy, torch) that may conflict with MusicGen. If you install both, one model might stop working properly.

For advanced users who want to experiment with Stable Audio Open:

```bash
# Method 1: Minimal installation (may still conflict)
pip install einops
pip install git+https://github.com/Stability-AI/stable-audio-tools.git --no-deps

# Method 2: Separate environment (recommended)
# Create a separate Python environment for Stable Audio
python -m venv stable_audio_env
# Activate it and install requirements there
```

## üöÄ Usage

### Step 1: Start the Server

```bash
# Launch the API server
python main.py --model-path "/path/to/your/llm/model.gguf" --profile "techno_minimal" --output-dir "./output" --clean
```

### Step 2: Start the Client with MIDI Sync

```bash
# Launch the client with MIDI synchronization
python client.py --api-url http://localhost:8000/api/v1
```

### Step 3: Configure Your DAW

1. **Start your client** (it will connect to loopMIDI automatically)
2. **Launch Bitwig** and configure MIDI Clock output
3. **Press Play ‚ñ∂Ô∏è in Bitwig** to start MIDI Clock
4. **Generate loops in DJ-IA Client** - they'll sync perfectly!

### Workflow Example

```bash
# Terminal 1: Start the server
python main.py --model-path "models/llama.gguf" --profile "techno_minimal"

# Terminal 2: Start the client
python client.py

# Then in Bitwig:
# 1. Add HW Instrument ‚Üí loopMIDI Port ‚Üí Send MIDI Clock ‚úÖ
# 2. Press Play ‚ñ∂Ô∏è
# 3. Generate loops in DJ-IA - perfect sync! üéØ
```

## üéÆ DJ-IA Client Commands

### Real-time Loop Generation

The client provides an interactive interface for generating loops:

```
üí¨ Command (or Enter for auto-generation):
```

### Available Commands

| Command              | Description                       | Example            |
| -------------------- | --------------------------------- | ------------------ |
| **[Enter]**          | Generate a new loop automatically |                    |
| **Text description** | Generate specific content         | `deep techno kick` |
| **s [stems]**        | Specify instruments               | `s drums,bass`     |
| **b [bpm]**          | Change tempo                      | `b 130`            |
| **k [key]**          | Change musical key                | `k F minor`        |
| **y [style]**        | Change style                      | `y ambient`        |
| **q**                | Quit application                  |                    |

### MIDI Sync Features

- ‚úÖ **Perfect timing alignment** with your DAW
- ‚úÖ **Automatic beat detection** and quantization
- ‚úÖ **No tempo drift** - always locked to DAW tempo
- ‚úÖ **Seamless transitions** between generated loops
- ‚úÖ **Real-time responsiveness** to DAW transport (Play/Stop)

### Server Parameters

- `--model-path`: Path to the LLM model (GGUF format recommended)
- `--profile`: Musical style (see below)
- `--output-dir`: Folder to save generated audio files
- `--clean`: Clean temporary files at startup (optional)
- `--audio-model`: Audio model to use (musicgen-small, musicgen-medium, musicgen-large, stable-audio-open)
- `--generation-duration`: Default duration in seconds for generated samples (default: 8.0)

### Client Parameters

- `--api-url`: Server URL (default: http://localhost:8000/api/v1)
- `--api-key`: API key if authentication is enabled
- `--style`: Default musical style (default: techno_minimal)
- `--bpm`: Default tempo (default: 126)
- `--key`: Default musical key (default: C minor)
- `--sample-rate`: Audio sample rate (default: 44100)

### Available Profiles

1. **techno_minimal**: Minimalist and deep techno at 126 BPM
2. **experimental**: Experimental and avant-garde sounds at 130 BPM
3. **rock**: Energetic rock elements at 120 BPM
4. **hip_hop**: Captivating hip-hop beats at 90 BPM
5. **jungle_dnb**: Fast breakbeats and deep bass at 174 BPM
6. **dub**: Spacious sounds with echoes and reverberations at 70 BPM
7. **deep_house**: Deep and melodic house grooves at 124 BPM
8. **downtempo_ambient**: Atmospheric and meditative soundscapes at 85 BPM
9. **classical**: Electronic reinterpretations of classical music at 110 BPM
10. **trip_hop**: Heavy beats and melancholic melodies at 95 BPM

## üß© System Architecture

### Server Components

- **LLM DJ Brain**: Makes creative decisions and determines which audio elements to add/modify
- **Audio Generation Engine**: Uses MusicGen or Stable Audio to create audio samples
- **Demucs**: Analyzes and separates samples into their instrumental components (stems)
- **Spectral Analysis Engine**: Intelligent analysis to avoid instrument overlaps
- **REST API**: Serves generated content to clients

### Client Components

- **MIDI Clock Manager**: Receives and processes MIDI Clock from DAWs
- **Audio Layer Manager**: Manages playback, mixing, and effects
- **Synchronization Engine**: Ensures perfect timing alignment
- **User Interface**: Interactive command prompt for real-time control

### üéõÔ∏è MIDI Clock Synchronization

The client features professional-grade MIDI Clock synchronization:

1. **DAW Integration**: Receives MIDI Clock from your DAW (Bitwig, Ableton, etc.)
2. **Precise Timing**: All loops start exactly on beat 1 of measures
3. **Transport Sync**: Responds to DAW Play/Stop/Continue commands
4. **No Drift**: Perfect tempo lock without accumulated timing errors
5. **Real-time**: New loops integrate seamlessly into the existing timeline

### üéµ Audio Generation Models

DJ-IA supports multiple AI audio generation models:

1. **MusicGen (Default)**: Facebook's audio generation model

   - `musicgen-small`: Faster, lower resource usage
   - `musicgen-medium`: Good balance of quality and performance
   - `musicgen-large`: Highest quality, but slower

2. **Stable Audio Open**: Stability AI's audio generation model
   - Different textures and styles compared to MusicGen
   - Higher sample rate (44.1kHz vs 32kHz)

## üéØ Professional DJ Workflow

### Recommended Setup

1. **DAW**: Use Bitwig Studio, Ableton Live, or your preferred DAW
2. **MIDI Routing**: Configure virtual MIDI (loopMIDI on Windows)
3. **Audio Routing**: Use virtual audio cables if needed
4. **Monitoring**: Monitor DJ-IA output alongside your main mix

### Integration Tips

- **Use DJ-IA loops as stems** in your DAW tracks
- **Layer AI-generated content** with your own samples
- **Sync multiple DJ-IA clients** for complex arrangements
- **Record the output** for post-production work

### Performance Considerations

- **Server**: Requires GPU for AI generation (can run on separate machine)
- **Client**: Lightweight, can run on any machine with audio output
- **Network**: Local network recommended for minimal latency
- **MIDI**: Ultra-low latency MIDI Clock ensures perfect sync

## üîß Troubleshooting

### MIDI Sync Issues

- **No MIDI Clock received**: Check loopMIDI port configuration in DAW
- **Timing drift**: Ensure DAW is sending MIDI Clock, not just MIDI data
- **Port not found**: Verify loopMIDI is running and port is created
- **Permission errors**: Run loopMIDI as administrator if needed

### Known Issues

- **CUDA Errors**: Check PyTorch/CUDA version compatibility
- **Audio dropouts**: Increase audio buffer size in system settings
- **Memory errors**: Use smaller LLM models or increase system RAM
- **Network timeouts**: Ensure server is running and accessible
- **Rubberband not found**: Verify Rubberband CLI is installed and in PATH
- **Time-stretching errors**: Check that Rubberband CLI is accessible from command line

### Performance Optimization

- **Server**: Use GPU acceleration, sufficient RAM, fast storage
- **Client**: Dedicated audio interface, low-latency audio drivers
- **Network**: Use local network, avoid WiFi for critical timing
- **System**: Disable unnecessary services, optimize for real-time audio
- **Windows**: Ensure Rubberband CLI is in PATH and accessible

## ü§ù Contribution

Contributions are welcome! Areas of particular interest:

- **Additional DAW integrations** (Logic Pro, Cubase, etc.)
- **VST plugin development** for direct DAW integration
- **Advanced MIDI features** (tempo changes, time signatures)
- **Multi-client synchronization** for complex setups
- **Performance optimizations** for real-time use

1. Fork the project
2. Create a branch for your feature (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üôè Acknowledgements

- [Audiocraft/MusicGen](https://github.com/facebookresearch/audiocraft) for audio generation
- [Stable Audio Tools](https://github.com/Stability-AI/stable-audio-tools) for alternative audio generation
- [Demucs](https://github.com/facebookresearch/demucs) for audio source separation
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) for optimized LLM inference
- [Pygame](https://www.pygame.org) for audio playback
- [Librosa](https://librosa.org) for audio processing
- [python-rtmidi/mido](https://github.com/SpotlightKid/python-rtmidi) for MIDI Clock support
- [loopMIDI](https://www.tobias-erichsen.de/software/loopmidi.html) for virtual MIDI ports
