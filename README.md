# üéß DJ-IA: AI-powered DJ System with Advanced Spectral Analysis

DJ-IA is an innovative AI-powered virtual DJ system capable of generating and mixing music in real-time. Using a Large Language Model (LLM) for creative decisions, AI audio models for generation, and Demucs for spectral analysis and isolation, DJ-IA creates dynamic and evolving music sessions in various styles.

‚ö†Ô∏è **IMPORTANT: Proof of Concept** ‚ö†Ô∏è  
This project is currently in proof of concept (POC) stage. Some music styles work better than others, and the code contains unused or experimental sections that haven't been cleaned up yet. The overall architecture is functional but continues to evolve.

Note that sometimes the timing alignment between layers isn't always optimal. This aspect will be improved in future versions.

## Demonstration

üé¨ **[Download video demonstration with sound](./example/poc_ai_dj.mp4)**

![DJ-IA Banner](https://placehold.co/800x200/1a1a1a/FFFFFF?text=DJ-IA)

## ‚ú® Features

- üß† Generative AI for DJ decisions and audio generation
- üîä **NEW: Spectral analysis and stem separation for intelligent mixing**
- üé≠ **NEW: Intelligent selection of complementary instruments**
- üéπ **NEW: Respect for LLM stem preferences (even with low energy)**
- üß© **NEW: Support for multiple audio generation models (MusicGen and Stable Audio Open)**
- üéõÔ∏è Real-time audio layer management system (max 3 simultaneous layers)
- üéöÔ∏è Audio effects: filters, panning, reverb, and delay
- üéµ Support for 10 different musical styles
- üîÑ Synchronized transitions and natural musical progression
- üó£Ô∏è Voice interventions generated by TTS

## üéÆ NEW: Live Mode

DJ-IA now features an innovative **Live Mode** designed for real-time collaboration between AI and human DJs during performances!

### Live Session Concept

Unlike the traditional DJ-IA mode where the AI manages multiple layers simultaneously, Live Mode generates a single loopable sample every 30 seconds, allowing human DJs to blend these samples into their mix in real-time.

```bash
# Launch in Live Mode
python main.py --model-path "/path/to/your/llm/model.gguf" --mode live --profile "techno_minimal" --output-dir "./output" --sample-interval 30
```

### How Live Mode Works

1. **Sequential Generation**: Instead of building complex layered compositions, the AI generates a new high-quality loopable sample every 30 seconds
2. **Human-AI Collaboration**: The human DJ receives these samples and incorporates them into their mix using their preferred DJ software (Bitwig, Ableton, etc.)
3. **Adaptive AI**: The LLM remembers previously generated samples and creates complementary new elements that follow a musical progression
4. **Perfect Loops**: All generated samples are automatically processed for perfect looping, with beat detection and time-stretching to match the target tempo
5. **Ready to Use**: Samples are immediately playable and perfectly quantized to the session's BPM

### Creative Applications

This mode enables several exciting creative possibilities:

- **Live DJ Augmentation**: Use AI-generated samples as additional elements in your DJ sets
- **Improvised Productions**: Build tracks on-the-fly by layering and manipulating the AI-generated loops
- **Creative Constraints**: Challenge yourself to work with whatever the AI provides every 30 seconds
- **Sound Design Source**: Use the generated samples as starting points for further processing in your DAW
- **Style Exploration**: Quickly experiment with different musical styles and aesthetics

### Seamless Transitions

Live Mode features perfectly seamless transitions between samples:

- **Gapless Playback**: No audio dropouts or pauses between sample changes
- **Beat-Synchronized**: All transitions occur exactly on beat boundaries
- **Crossfade Support**: Subtle automatic crossfades prevent clicks and pops
- **Buffer Management**: Advanced double-buffer technique ensures audio continuity
- **Tempo-Locked**: All transitions respect the musical tempo for rhythmic coherence

# Command Interface for DJ-IA Live Mode

## üéÆ Live Control and Command Interface

DJ-IA Live Mode features an interactive command interface allowing DJs to control sample generation in real-time during performances.

### Intuitive Command Prompt

A permanent command prompt is displayed, offering a clear interaction point even while music is playing:

```
üí¨ Command (r=reject, g=generate, q=quit, h=help) >
```

The system provides status updates every 15 seconds and before generating each new sample, ensuring you stay informed about session timing without interrupting your creative flow with excessive notifications.

### Available Commands

| Command            | Description                                              | Example       |
| ------------------ | -------------------------------------------------------- | ------------- |
| üîÑ `r`, `next`     | Reject current sample and immediately generate a new one | `r`           |
| üéØ `g`, `generate` | Request a specific sample from the LLM                   | `g deep bass` |
| ‚ùå `q`, `quit`     | Gracefully exit the application                          | `q`           |
| ‚ÑπÔ∏è `h`, `help`     | Display help and available commands                      | `h`           |

### User-Directed Generation

The `g` (generate) command is particularly powerful, allowing you to explicitly request specific sonic elements:

```
üí¨ Command > g atmospheric pad with reverb
üéØ Generating specific sample: 'atmospheric pad with reverb'
‚úì Generating 'techno_pad' in progress...
```

The system:

1. Analyzes your request to determine the most appropriate sample type
2. Passes your request to the LLM to influence its creative decision
3. Enriches the MusicGen prompt with your specific terms
4. Triggers immediate generation without waiting for the normal interval

### Creative Usage Examples

- `g powerful kick` : Get a strong kick drum to reinforce the rhythm section
- `g deep sub bass` : Add a deep bass for drop moments
- `g spacey pad with delay` : Create an ethereal atmosphere for breakdowns
- `g glitchy percussion` : Add experimental rhythmic elements
- `g melodic synth in C minor` : Get a melodic element in the current key

This interface enables truly interactive DJ performances where you can guide the AI in specific creative directions while retaining the spontaneity and originality of AI generation.

### Technical Implementation

The Live Mode uses a dedicated `LiveSession` class that:

- Manages a continuous generation cycle based on a configurable interval
- Processes each sample for perfect looping using onset detection and time-stretching
- Maintains session history to inform the LLM of previously generated samples
- Uses specialized LLM prompts optimized for the live generation context
- Provides a real-time preview of generated samples through pygame audio playback

This feature represents an experimental new approach to human-AI music collaboration, focusing on augmenting human creativity rather than replacing it. The system serves as a creative partner, continuously offering new musical ideas while letting the human DJ maintain control over the final mix.

## üõ†Ô∏è Installation

### Prerequisites

- Python 3.10 or higher
- NVIDIA graphics card with CUDA for optimal performance (recommended)
- At least 8GB of RAM
- At least 2GB of free disk space

### Setting up the environment

```bash
# Create and activate a virtual environment
python -m venv env

# On Windows
.\env\Scripts\activate

# On macOS/Linux
source env/bin/activate

# Install base dependencies
pip install numpy==1.24.3

# Install PyTorch with CUDA
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# Install necessary tools
pip install setuptools wheel

# Install main libraries
pip install audiocraft pygame llama-cpp-python tqdm librosa

# Install Demucs for source separation
pip install demucs

# Install audio libraries
pip install pyrubberband pedalboard soundfile sounddevice pyttsx3
```

### Stable Audio Open (Optional)

‚ö†Ô∏è **IMPORTANT: Dependency Conflict Warning** ‚ö†Ô∏è
Stable Audio Open uses different versions of some dependencies (like numpy, torch) that may conflict with MusicGen. If you install both, one model might stop working properly.

For advanced users who want to experiment with Stable Audio Open:

```bash
# Method 1: Minimal installation (may still conflict)
pip install einops
pip install git+https://github.com/Stability-AI/stable-audio-tools.git --no-deps

# Method 2: Separate environment (recommended)
# Create a separate Python environment for Stable Audio
python -m venv stable_audio_env
# Activate it and install requirements there
```

## üöÄ Usage

### Launch with MusicGen (Default)

```bash
python main.py --model-path "/path/to/your/llm/model.gguf" --profile "techno_minimal" --output-dir "./output" --clean
```

### Launch with different Audio Models

```bash
# Using MusicGen Medium (default)
python main.py --profile "techno_minimal" --audio-model musicgen-medium

# Using MusicGen Small (faster but lower quality)
python main.py --profile "techno_minimal" --audio-model musicgen-small

# Using MusicGen Large (higher quality but slower)
python main.py --profile "techno_minimal" --audio-model musicgen-large

# Using Stable Audio Open (if installed)
python main.py --profile "techno_minimal" --audio-model stable-audio-open --generation-duration 5.0
```

### Parameters

- `--model-path`: Path to the LLM model (GGUF format recommended)
- `--profile`: Musical style (see below)
- `--output-dir`: Folder to save generated audio files
- `--clean`: Clean temporary files at startup (optional)
- `--audio-model`: Audio model to use (musicgen-small, musicgen-medium, musicgen-large, stable-audio-open)
- `--generation-duration`: Default duration in seconds for generated samples (default: 8.0)

### Available Profiles

1. **techno_minimal**: Minimalist and deep techno at 126 BPM
2. **experimental**: Experimental and avant-garde sounds at 130 BPM
3. **rock**: Energetic rock elements at 120 BPM
4. **hip_hop**: Captivating hip-hop beats at 90 BPM
5. **jungle_dnb**: Fast breakbeats and deep bass at 174 BPM
6. **dub**: Spacious sounds with echoes and reverberations at 70 BPM
7. **deep_house**: Deep and melodic house grooves at 124 BPM
8. **downtempo_ambient**: Atmospheric and meditative soundscapes at 85 BPM
9. **classical**: Electronic reinterpretations of classical music at 110 BPM
10. **trip_hop**: Heavy beats and melancholic melodies at 95 BPM

## üß© System Architecture

DJ-IA consists of several modules:

- **LLM DJ Brain**: Makes creative decisions and determines which audio elements to add/modify
- **Audio Generation Engine**: Uses MusicGen or Stable Audio to create audio samples
- **Demucs**: Analyzes and separates samples into their instrumental components (stems)
- **Spectral Analysis Engine**: Intelligent analysis to avoid instrument overlaps
- **LayerManager**: Manages playback, mixing, and effects of different audio layers
- **TTS Engine**: Generates voice interventions

The system maintains a maximum of 3 simultaneous layers at all times, with only one rhythmic element at a time to ensure mix coherence.

### üéõÔ∏è Spectral Analysis and Stem Separation

The system now integrates advanced spectral analysis and separation technology:

1. **Sample Analysis**: Each generated sample is analyzed with Demucs to identify its composition (drums, bass, vocals, etc.)
2. **Intelligent Stem Selection**: The LLM can request specific stems (drums, bass, other) which are respected even with low energy
3. **Overlap Avoidance**: DJ-IA naturally avoids having multiple rhythmic layers simultaneously
4. **Targeted Extraction**: Only the most relevant element for the mix is extracted and used
5. **Adapted Effects**: Effects are automatically optimized for the type of instrument used

### üéµ Audio Generation Models

DJ-IA now supports multiple AI audio generation models:

1. **MusicGen (Default)**: Facebook's audio generation model, available in three sizes:

   - `musicgen-small`: Faster, lower resource usage
   - `musicgen-medium`: Good balance of quality and performance
   - `musicgen-large`: Highest quality, but slower and higher resource usage

2. **Stable Audio Open**: Stability AI's open audio generation model
   - Generally creates different textures and styles compared to MusicGen
   - Installed separately due to dependency conflicts
   - Higher sample rate (44.1kHz vs 32kHz for MusicGen)

### Layer Management

The system includes advanced audio layer management:

1. **3-Layer Limit**: The system always maintains a maximum of 3 simultaneous layers
2. **Proactive Management**: The LLM is notified when it approaches the limit (2 active layers)
3. **Replacement Strategy**: The LLM intelligently chooses which layers to replace to maintain musical interest
4. **Single Rhythmic Track**: Only one rhythmic layer (drums/percussion) can be active at a time

### Current Limitations

- The quality of generated samples varies depending on the musical style
- Some audio effects (like complex reverb) are implemented but rarely used
- The techno_minimal, hip_hop, and trip_hop profiles generally give the best results
- Performance depends heavily on your GPU power
- Spectral analysis adds additional delay between DJ decisions
- Stable Audio and MusicGen have dependency conflicts and may not work well together in the same Python environment

## üìä DJ Behavior

Depending on the chosen profile, DJ-IA will adopt different behaviors:

- **techno_minimal**: Progressive and hypnotic construction
- **experimental**: Bold contrasts and rhythmic breaks
- **rock**: Energetic progression with guitars and drums
- **hip_hop**: Syncopated grooves and deep bass
- **jungle_dnb**: Fast tempos and complex breakbeats
- **dub**: Deep sound spaces with delays and echoes
- **deep_house**: Fluid progression with jazzy and soulful elements
- **downtempo_ambient**: Slow and atmospheric evolutions with immersive textures
- **classical**: Fusion of orchestral elements with modern rhythms
- **trip_hop**: Dark cinematic atmospheres with heavy beats and vinyl scratches

## DJ-IA Client for Music Loop Generation

The DJ-IA client is a command-line interface that allows you to generate and continuously play musical loops through the DJ-IA API. It's perfect for testing loop generation or quickly creating musical ideas for your projects.

### Features

- **Continuous Generation**: Create new loops without interrupting the currently playing sound
- **Seamless Transitions**: Automatic crossfades between loops
- **Interactive Interface**: Generate loops by simply pressing Enter or with custom prompts
- **Real-time Control**: Modify BPM, key, style, and stems during execution
- **Automatic Saving**: All generated loops are saved locally for future use

### Installation

```bash
# Make sure you have the required dependencies
pip install requests numpy pygame sounddevice soundfile python-dotenv
```

### Usage

#### Basic Startup

```bash
python client.py --api-key YOUR_API_KEY
```

#### Advanced Configuration

```bash
python client.py --api-url http://localhost:8000/api/v1 --api-key YOUR_API_KEY --style techno_minimal --bpm 126 --key "C minor" --sample-rate 44100
```

#### Command-line Arguments

- `--api-url`: URL of the DJ-IA API (default: http://localhost:8000/api/v1)
- `--api-key`: Your DJ-IA API key (can also be set in .env file as DJ_IA_API_KEY)
- `--style`: Default musical style (default: techno_minimal)
- `--bpm`: Default tempo in beats per minute (default: 126)
- `--key`: Default musical key (default: C minor)
- `--sample-rate`: Audio sample rate in Hz (default: 44100)

### Interactive Commands

Once the client is running, you can use these commands:

- **[Enter]**: Generate a new loop with default settings
- **Any text**: Generate a loop based on this text description
- **s drums,bass**: Specify stems to extract (separates instruments)
- **b 130**: Change BPM to 130
- **k F minor**: Change key to F minor
- **y ambient**: Change musical style to ambient
- **q**: Quit the application

### Routing to Your DAW

To route audio to your DAW:

1. Install virtual audio routing software (Blackhole, VB-Cable, JACK Audio, etc.)
2. Configure your system audio output to use this virtual device
3. In your DAW, configure an audio track to receive input from this device

### Note About VST Development

We are currently working on a VST version of the DJ-IA system that would integrate directly with your DAW. However, we're experiencing some issues with audio rendering, particularly with buffer management causing clicks and pops in the audio output. We're actively addressing these issues and will release the VST when it reaches a stable state.

For now, the client.py approach offers the most reliable way to use DJ-IA with your DAW via virtual audio routing.

## üîß Troubleshooting

### Known Issues

- **CUDA Errors**: Check that your PyTorch version matches your CUDA version
- **Choppy Audio**: Try increasing the audio buffer value in the `layer_manager.py` file
- **Memory Errors**: Free up RAM or reduce the size of the LLM model used
- **Demucs Errors**: Make sure Demucs is properly installed (`pip install demucs`)
- **Model Conflicts**: MusicGen and Stable Audio use conflicting dependencies; installing both may cause issues with one or both models

### Dependency Conflict Solutions

If you encounter issues with model dependencies:

1. **Use Docker**: Create separate Docker containers for each model
2. **Separate Environments**: Create separate virtual environments for MusicGen and Stable Audio
3. **Minimal Installation**: Use the `--no-deps` flag when installing Stable Audio Tools and manually install only the essential dependencies

## ü§ù Contribution

Contributions are welcome! Here's how you can contribute:

1. Fork the project
2. Create a branch for your feature (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üôè Acknowledgements

- [Audiocraft/MusicGen](https://github.com/facebookresearch/audiocraft) for audio generation
- [Stable Audio Tools](https://github.com/Stability-AI/stable-audio-tools) for alternative audio generation
- [Demucs](https://github.com/facebookresearch/demucs) for audio source separation
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) for optimized LLM inference
- [Pygame](https://www.pygame.org) for audio playback
- [Librosa](https://librosa.org) for audio processing
